2022.01.18 00:04:24 INFO  es[][o.e.n.Node] version[7.16.2], pid[40], build[default/tar/2b937c44140b6559905130a8650c64dbd0879cfb/2021-12-18T19:42:46.604893745Z], OS[Linux/5.10.60.1-microsoft-standard-WSL2/amd64], JVM[Alpine/OpenJDK 64-Bit Server VM/11.0.12/11.0.12+7-alpine-r0]
2022.01.18 00:04:24 INFO  es[][o.e.n.Node] JVM home [/usr/lib/jvm/java-11-openjdk]
2022.01.18 00:04:24 INFO  es[][o.e.n.Node] JVM arguments [-XX:+UseG1GC, -Djava.io.tmpdir=/opt/sonarqube/temp, -XX:ErrorFile=../logs/es_hs_err_pid%p.log, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -Djna.tmpdir=/opt/sonarqube/temp, -XX:-OmitStackTraceInFastThrow, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=COMPAT, -Dcom.redhat.fips=false, -Xmx512m, -Xms512m, -XX:MaxDirectMemorySize=256m, -XX:+HeapDumpOnOutOfMemoryError, -Des.path.home=/opt/sonarqube/elasticsearch, -Des.path.conf=/opt/sonarqube/temp/conf/es, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=false]
2022.01.18 00:04:25 INFO  es[][o.e.p.PluginsService] loaded module [analysis-common]
2022.01.18 00:04:25 INFO  es[][o.e.p.PluginsService] loaded module [lang-painless]
2022.01.18 00:04:25 INFO  es[][o.e.p.PluginsService] loaded module [parent-join]
2022.01.18 00:04:25 INFO  es[][o.e.p.PluginsService] loaded module [transport-netty4]
2022.01.18 00:04:25 INFO  es[][o.e.p.PluginsService] no plugins loaded
2022.01.18 00:04:26 INFO  es[][o.e.e.NodeEnvironment] using [1] data paths, mounts [[/opt/sonarqube/data (C:\134)]], net usable_space [340.1gb], net total_space [476.1gb], types [9p]
2022.01.18 00:04:26 INFO  es[][o.e.e.NodeEnvironment] heap size [512mb], compressed ordinary object pointers [true]
2022.01.18 00:04:29 INFO  es[][o.e.n.Node] node name [sonarqube], node ID [OokrsvIiS16rKkddJWLyGg], cluster name [sonarqube], roles [data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
2022.01.18 00:04:39 INFO  es[][o.e.t.NettyAllocator] creating NettyAllocator with the following configs: [name=unpooled, suggested_max_allocation_size=256kb, factors={es.unsafe.use_unpooled_allocator=null, g1gc_enabled=true, g1gc_region_size=1mb, heap_size=512mb}]
2022.01.18 00:04:39 INFO  es[][o.e.d.DiscoveryModule] using discovery type [zen] and seed hosts providers [settings]
2022.01.18 00:04:40 INFO  es[][o.e.g.DanglingIndicesState] gateway.auto_import_dangling_indices is disabled, dangling indices will not be automatically detected or imported and must be managed manually
2022.01.18 00:04:41 INFO  es[][o.e.n.Node] initialized
2022.01.18 00:04:41 INFO  es[][o.e.n.Node] starting ...
2022.01.18 00:04:41 INFO  es[][o.e.t.TransportService] publish_address {127.0.0.1:39903}, bound_addresses {127.0.0.1:39903}
2022.01.18 00:04:43 WARN  es[][o.e.b.BootstrapChecks] max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]
2022.01.18 00:04:43 INFO  es[][o.e.c.c.Coordinator] cluster UUID [rRZxIi1nQzKvrr6DbnhHKA]
2022.01.18 00:04:44 INFO  es[][o.e.c.s.MasterService] elected-as-master ([1] nodes joined)[{sonarqube}{OokrsvIiS16rKkddJWLyGg}{k8l2bfc2Rg2RzRIWzYvzZQ}{127.0.0.1}{127.0.0.1:39903}{cdfhimrsw} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 2, version: 42, delta: master node changed {previous [], current [{sonarqube}{OokrsvIiS16rKkddJWLyGg}{k8l2bfc2Rg2RzRIWzYvzZQ}{127.0.0.1}{127.0.0.1:39903}{cdfhimrsw}]}
2022.01.18 00:04:44 INFO  es[][o.e.c.s.ClusterApplierService] master node changed {previous [], current [{sonarqube}{OokrsvIiS16rKkddJWLyGg}{k8l2bfc2Rg2RzRIWzYvzZQ}{127.0.0.1}{127.0.0.1:39903}{cdfhimrsw}]}, term: 2, version: 42, reason: Publication{term=2, version=42}
2022.01.18 00:04:44 INFO  es[][o.e.h.AbstractHttpServerTransport] publish_address {127.0.0.1:9001}, bound_addresses {127.0.0.1:9001}
2022.01.18 00:04:44 INFO  es[][o.e.n.Node] started
2022.01.18 00:04:45 INFO  es[][o.e.g.GatewayService] recovered [7] indices into cluster_state
2022.01.18 00:05:07 INFO  es[][o.e.c.r.a.AllocationService] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[metadatas][0]]]).
2022.01.18 00:17:18 WARN  es[][o.e.h.AbstractHttpServerTransport] handling request [null][POST][/components/_refresh][Netty4HttpChannel{localAddress=/127.0.0.1:9001, remoteAddress=/127.0.0.1:39762}] took [6533ms] which is above the warn threshold of [5000ms]
2022.01.18 00:18:00 WARN  es[][o.e.t.ThreadPool] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1f4196ca, interval=1s}] took [6203ms] which is above the warn threshold of [5000ms]
2022.01.18 00:18:00 WARN  es[][o.e.h.AbstractHttpServerTransport] handling request [null][POST][/projectmeasures/auth/_search?typed_keys=true&max_concurrent_shard_requests=5&search_type=query_then_fetch&batched_reduce_size=512][Netty4HttpChannel{localAddress=/127.0.0.1:9001, remoteAddress=/127.0.0.1:39876}] took [6825ms] which is above the warn threshold of [5000ms]
2022.01.18 00:22:46 WARN  es[][o.e.t.ThreadPool] timer thread slept for [11.6s/11606ms] on absolute clock which is above the warn threshold of [5000ms]
2022.01.18 00:22:47 WARN  es[][o.e.t.ThreadPool] timer thread slept for [11.6s/11606464333ns] on relative clock which is above the warn threshold of [5000ms]
2022.01.18 00:23:56 WARN  es[][o.e.t.ThreadPool] timer thread slept for [5.5s/5515ms] on absolute clock which is above the warn threshold of [5000ms]
2022.01.18 00:23:57 WARN  es[][o.e.t.ThreadPool] timer thread slept for [5.5s/5515438665ns] on relative clock which is above the warn threshold of [5000ms]
2022.01.18 00:57:38 WARN  es[][o.e.m.j.JvmGcMonitorService] [gc][young][2993][8] duration [1s], collections [1]/[1s], total [1s]/[1.2s], memory [323.8mb]->[323.8mb]/[512mb], all_pools {[young] [264mb]->[0b]/[0b]}{[old] [43.8mb]->[43.7mb]/[512mb]}{[survivor] [16mb]->[19mb]/[0b]}
2022.01.18 00:57:39 WARN  es[][o.e.m.j.JvmGcMonitorService] [gc][2993] overhead, spent [1s] collecting in the last [1s]
2022.01.18 02:02:43 INFO  es[][o.e.m.j.JvmGcMonitorService] [gc][young][6823][10] duration [788ms], collections [1]/[1.7s], total [788ms]/[2s], memory [175.3mb]->[62.2mb]/[512mb], all_pools {[young] [111mb]->[0b]/[0b]}{[old] [61.3mb]->[61.2mb]/[512mb]}{[survivor] [3mb]->[1mb]/[0b]}
2022.01.18 02:02:44 INFO  es[][o.e.m.j.JvmGcMonitorService] [gc][6823] overhead, spent [788ms] collecting in the last [1.7s]
2022.01.18 03:00:34 WARN  es[][o.e.t.ThreadPool] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1f4196ca, interval=1s}] took [9195ms] which is above the warn threshold of [5000ms]
2022.01.18 03:00:34 WARN  es[][o.e.t.ThreadPool] timer thread slept for [9.1s/9196ms] on absolute clock which is above the warn threshold of [5000ms]
2022.01.18 10:40:44 WARN  es[][o.e.t.ThreadPool] timer thread slept for [9.1s/9195759987ns] on relative clock which is above the warn threshold of [5000ms]
2022.01.18 10:40:44 WARN  es[][o.e.t.ThreadPool] timer thread slept for [7.6h/27610921ms] on absolute clock which is above the warn threshold of [5000ms]
2022.01.18 10:45:11 WARN  es[][o.e.t.ThreadPool] timer thread slept for [22.7s/22732ms] on absolute clock which is above the warn threshold of [5000ms]
2022.01.18 10:45:11 WARN  es[][o.e.t.ThreadPool] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1f4196ca, interval=1s}] took [22732ms] which is above the warn threshold of [5000ms]
2022.01.18 10:45:11 WARN  es[][o.e.t.ThreadPool] timer thread slept for [22.7s/22732593628ns] on relative clock which is above the warn threshold of [5000ms]
2022.01.18 10:57:48 INFO  es[][o.e.m.j.JvmGcMonitorService] [gc][11253] overhead, spent [503ms] collecting in the last [1s]
2022.01.18 12:13:06 WARN  es[][o.e.t.ThreadPool] timer thread slept for [13.7m/827256ms] on absolute clock which is above the warn threshold of [5000ms]
2022.01.18 12:13:07 WARN  es[][o.e.t.ThreadPool] timer thread slept for [13.7m/827255882670ns] on relative clock which is above the warn threshold of [5000ms]
2022.01.18 12:56:18 WARN  es[][o.e.t.ThreadPool] timer thread slept for [19.5s/19544ms] on absolute clock which is above the warn threshold of [5000ms]
2022.01.18 12:56:18 WARN  es[][o.e.t.ThreadPool] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@1f4196ca, interval=1s}] took [19543ms] which is above the warn threshold of [5000ms]
2022.01.18 12:56:18 WARN  es[][o.e.t.ThreadPool] timer thread slept for [19.5s/19543607128ns] on relative clock which is above the warn threshold of [5000ms]
2022.01.18 13:08:58 WARN  es[][o.e.m.j.JvmGcMonitorService] [gc][18237] overhead, spent [565ms] collecting in the last [1s]
2022.01.18 17:00:19 WARN  es[][o.e.t.ThreadPool] timer thread slept for [8.9m/534637ms] on absolute clock which is above the warn threshold of [5000ms]
2022.01.18 17:00:19 WARN  es[][o.e.t.ThreadPool] timer thread slept for [8.9m/534637297781ns] on relative clock which is above the warn threshold of [5000ms]
2022.01.18 17:00:35 WARN  es[][o.e.t.ThreadPool] timer thread slept for [5s/5041ms] on absolute clock which is above the warn threshold of [5000ms]
2022.01.18 17:00:35 WARN  es[][o.e.t.ThreadPool] timer thread slept for [5s/5041288189ns] on relative clock which is above the warn threshold of [5000ms]
2022.01.18 17:11:41 WARN  es[][o.e.t.ThreadPool] timer thread slept for [11.1m/666027ms] on absolute clock which is above the warn threshold of [5000ms]
2022.01.18 17:37:17 WARN  es[][o.e.t.ThreadPool] timer thread slept for [24.4m/1469801ms] on absolute clock which is above the warn threshold of [5000ms]
2022.01.18 21:38:21 WARN  es[][o.e.t.ThreadPool] timer thread slept for [5.5s/5575ms] on absolute clock which is above the warn threshold of [5000ms]
2022.01.18 21:38:21 WARN  es[][o.e.t.ThreadPool] timer thread slept for [5.5s/5574546873ns] on relative clock which is above the warn threshold of [5000ms]
2022.01.18 23:27:32 WARN  es[][o.e.t.ThreadPool] timer thread slept for [1.8h/6550559ms] on absolute clock which is above the warn threshold of [5000ms]
2022.01.18 23:29:43 WARN  es[][o.e.t.ThreadPool] timer thread slept for [5.4s/5427ms] on absolute clock which is above the warn threshold of [5000ms]
2022.01.18 23:29:44 WARN  es[][o.e.t.ThreadPool] timer thread slept for [5.4s/5426221839ns] on relative clock which is above the warn threshold of [5000ms]
